{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, datasets\n",
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정하기\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "num_epoch = 10\n",
    "\n",
    "# 학습가중치와 텐서보드 로그저장\n",
    "ckpt_dir = './checkpoint'\n",
    "log_dir = './log'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 구축\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 넷의 부모클래스에서 속성 상속받아옴\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 네트워크 구축에 필요한 레이어 초기화 \n",
    "        self.conv1 = nn.Conv2d(1, 10, 5, 1, 0, 0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(10, 20, 5, 1, 0, 0)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.relu1_fc1 = nn.ReLU()\n",
    "        self.drop1_fc1 = nn.Dropout2d(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(50, 10)\n",
    "        \n",
    "    # 위의 초기화된 레이어를 연결하여 네트워크를 구축하였다\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        # 텐서의 1차원은 자동, 2차원은 320 크기로\n",
    "        # 개수가 6400개이면 앞은 20이 되어야함 그런데 -1하면 알아서 맞춰줌\n",
    "        x = x.view(-1, 320)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1_fc1(x)\n",
    "        x = self.drop1_fc1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크를 저장 또는 불러오는 함수\n",
    "def save(ckpt_dir, net, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "        torch.save({'net': net.state_dict(), 'optim': optim.state_dict()},\n",
    "                   './%s/model_epoch%d.pth' % (ckpt_dir, epoch))\n",
    "        \n",
    "def load(ckpt_dir, net, optim):\n",
    "    #경로의 모든파일 가져오기\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    #알파벳순으로 정렬 마지막이 최근\n",
    "    ckpt_lst.sort()\n",
    "    \n",
    "    # 파이토치객체를 최근것을 불러와서 dict형태로 저장\n",
    "    dict_model = torch.load('./%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "    \n",
    "    #네트워크의 파라미터(가중치)를 가져온것으로 업데이트\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    # 옵티마이저도 동일하게\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "    return net, optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mnist데이터 불러오기\n",
    "# 전처리과정을 결합(compose)한다\n",
    "#이미지데이터를 텐서데이터로 바꾸고, 0~1로 정규화\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "#데이터셋이 존재하지않으면 다운로드, 라벨데이터도 같이\n",
    "dataset = datasets.MNIST(download=True, root='./', train=True, transform=transform)\n",
    "\n",
    "#데이터셋을 배치단위로 가져온다,\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# 데이터셋 데이터의 전체개수\n",
    "num_data = len(loader.dataset)\n",
    "# 전체데이터를 배치단위로 나누어 전체배치수 계산\n",
    "num_batch = np.ceil(num_data / batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 설정 및 필요한 손실함수 구현\n",
    "# 사용자 정의 신경망이다. device는 cpu또는 gpu\n",
    "net = Net().to(device)\n",
    "#신경망의 가중치와 편향, 훈련하면서 최적화됨\n",
    "params = net.parameters()\n",
    "\n",
    "# 손실함수, 모델예측과 실제의 차이확인\n",
    "fn_loss = nn.CrossEntropyLoss().to(device)\n",
    "#소프트맥수 함수를 통과시켜 각 클래스에 대한 확률분포로 변환\n",
    "fn_pred = lambda output: torch.softmax(output, dim=1)\n",
    "# 예측정확도 계산, 확률이 최대인것을 찾고 답이 같으면 평균을 취해서 정확도 산출\n",
    "fn_acc = lambda pred, label: ((pred.max(dim=1)[1] == label).type(torch.float)).mean()\n",
    "# adam 최적화알고리즘으로 파라미터를 lr에 따라업데이트\n",
    "optim = torch.optim.Adam(params, lr=lr)\n",
    "# 텐서보드에 손실, 정확도등의 그래프 확인\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 학습 시작\n",
    "#여러번 학습을 한다, 각 반복을 에폭이라한다\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    #신경만을 훈련 모드로 설정=>dropout,BN은 훈련시에만 활성화해주어야한다\n",
    "    net.train()\n",
    "    #각 배치마다의 값을저장 저장할 리스트\n",
    "    loss_arr = []\n",
    "    acc_arr = []\n",
    "    \n",
    "    # 데이터로더에서 배치단위, X,Y,데이터 가져오기\n",
    "    for batch, (input, label) in enumerate(loader, 1):\n",
    "        # 장치에 데이터를 넣어서 계산준비\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "        #순전파 신경망에 데이터를 전달해서 예측출력\n",
    "        output = net(input)\n",
    "        # 신경망의 출력으로 예측값 계산\n",
    "        pred = fn_pred(output)\n",
    "        # 그래디언트 초기화, 각 배치마다 새로운 그래디언트를 계산하기 위해\n",
    "        optim.zero_grad()\n",
    "        #예측과 레이블을 비교해서 손실계산\n",
    "        loss = fn_loss(output, label)\n",
    "        # 정확도도 동일\n",
    "        acc = fn_acc(pred, label)\n",
    "        # 각 가중치에 대한 손실함수의 그래디언트 계산 => 그래디언트를 보고 가중치를 늘리거나 줄이기를 결정\n",
    "        loss.backward()\n",
    "        # 옵티마이저로 계산한 그래디언트를가지고 가중치 업데이트\n",
    "        optim.step()\n",
    "        #지금 배치의 손실과 정확도 저장\n",
    "        loss_arr += [loss.item()]\n",
    "        acc_arr += [acc.item()]\n",
    "        #진행상황 출력\n",
    "        print('TRAIN: EPOCH %04d/%04d | BATCH %04d/$04d | LOSS: %.4f | ACC: %.4f' %\n",
    "              (epoch, num_epoch, num_batch, np.mean(loss_arr), np.mean(acc_arr)))\n",
    "        \n",
    "    #텐서보드 기록용\n",
    "    writer.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "    writer.add_scalar('acc', np.mean(acc_arr), epoch)\n",
    "    \n",
    "    #체크포인트 저장\n",
    "    save(ckpt_dir=ckpt_dir, net=net, optim=optim, epoch=epoch)\n",
    "#텐서보드 로깅을 마치고 객체닫기\n",
    "writer.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
